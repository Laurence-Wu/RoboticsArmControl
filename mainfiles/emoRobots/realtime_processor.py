# realtime_processor.py
"""
å®æ—¶æ•°æ®å¤„ç†å™¨ - ç›‘æ§é‡‡é›†æ–‡ä»¶å¹¶åº”ç”¨ç®—æ³•åˆ†æ

æ­¤è„šæœ¬ç›‘æ§data_collector_test.pyç”Ÿæˆçš„CSVæ–‡ä»¶ï¼Œ
æ¯2ç§’è¯»å–æ–°æ•°æ®ï¼Œåº”ç”¨alg.pyçš„ç®—æ³•é€»è¾‘ï¼Œ
å¹¶åœ¨ç»ˆç«¯è¾“å‡ºåˆ†ç±»ç»“æœã€‚

ä½¿ç”¨æ–¹æ³•:
1. å…ˆè¿è¡Œ data_collector_test.py å¼€å§‹æ•°æ®é‡‡é›†
2. å†è¿è¡Œæ­¤è„šæœ¬è¿›è¡Œå®æ—¶å¤„ç†
"""

import os
import time
import pandas as pd
import numpy as np
from datetime import datetime
import glob
from collections import deque
import threading
from scipy.signal import find_peaks

class RealtimeProcessor:
    """
    å®æ—¶å¤„ç†å™¨ç±»
    ç›‘æ§CSVæ–‡ä»¶å˜åŒ–å¹¶åº”ç”¨ç®—æ³•åˆ†æ
    """
    
    def __init__(self, monitor_directory="collected_data"):
        """
        åˆå§‹åŒ–å®æ—¶å¤„ç†å™¨
        
        Parameters:
        -----------
        monitor_directory : str
            ç›‘æ§çš„ç›®å½•è·¯å¾„
        """
        print("=" * 60)
        print("åˆå§‹åŒ–å®æ—¶æ•°æ®å¤„ç†å™¨")
        print("=" * 60)
        
        self.monitor_directory = monitor_directory
        self.met_file_path = None
        self.last_row_processed = 0
        self.processing_interval = 2.0  # 2ç§’å¤„ç†é—´éš”
        self.is_running = False
        
        # ç®—æ³•æƒé‡é…ç½®ï¼ˆä¸alg.pyä¿æŒä¸€è‡´ï¼‰
        self.weights = {
            'attention'  :  0.35,
            'engagement' :  0.25,
            'excitement' :  0.15,
            'interest'   :  0.15,
            'stress'     :  0.15,
            'relaxation' : -0.10,
        }
        
        # æ•°æ®ç¼“å†²åŒºå­˜å‚¨æœ€è¿‘çš„æ•°æ®ç”¨äºç®—æ³•å¤„ç†
        self.data_buffer = deque(maxlen=100)  # å­˜å‚¨æœ€è¿‘100ä¸ªæ•°æ®ç‚¹
        
        # åˆ†æç»“æœè®°å½•
        self.analysis_results = []
        
    def find_latest_met_file(self):
        """
        æŸ¥æ‰¾æœ€æ–°çš„performance metrics CSVæ–‡ä»¶
        
        Returns:
        --------
        str or None: æœ€æ–°æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å›None
        """
        pattern = os.path.join(self.monitor_directory, "realtime_met_*.csv")
        met_files = glob.glob(pattern)
        
        if not met_files:
            return None
            
        # æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶ï¼ˆæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼‰
        latest_file = max(met_files, key=os.path.getmtime)
        return latest_file
        
    def wait_for_data_file(self, timeout=60):
        """
        ç­‰å¾…æ•°æ®æ–‡ä»¶å‡ºç°
        
        Parameters:
        -----------
        timeout : int
            ç­‰å¾…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
        --------
        bool: æ˜¯å¦æˆåŠŸæ‰¾åˆ°æ–‡ä»¶
        """
        print(f"ğŸ“¡ æ­£åœ¨ç­‰å¾…æ•°æ®é‡‡é›†æ–‡ä»¶...")
        print(f"   ç›‘æ§ç›®å½•: {os.path.abspath(self.monitor_directory)}")
        print(f"   æŸ¥æ‰¾æ¨¡å¼: realtime_met_*.csv")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            self.met_file_path = self.find_latest_met_file()
            if self.met_file_path:
                print(f"âœ“ æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {os.path.basename(self.met_file_path)}")
                return True
            time.sleep(1)
            
        print(f"âŒ ç­‰å¾…è¶…æ—¶ï¼æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        print(f"ğŸ’¡ è¯·ç¡®ä¿å…ˆè¿è¡Œ data_collector_test.py å¼€å§‹æ•°æ®é‡‡é›†")
        return False
        
    def parse_met_labels(self, header_row):
        """
        è§£æperformance metricsæ ‡ç­¾
        
        Parameters:
        -----------
        header_row : list
            CSVæ–‡ä»¶çš„å¤´éƒ¨è¡Œ
            
        Returns:
        --------
        dict: å­—æ®µååˆ°ç´¢å¼•çš„æ˜ å°„
        """
        indices = {}
        for i, label in enumerate(header_row):
            if 'attention' in label.lower() and 'isactive' not in label.lower():
                indices['attention'] = i
            elif 'eng' in label.lower() and 'isactive' not in label.lower():
                indices['engagement'] = i
            elif 'exc' in label.lower() and 'isactive' not in label.lower():
                indices['excitement'] = i
            elif 'int' in label.lower() and 'isactive' not in label.lower():
                indices['interest'] = i
            elif 'str' in label.lower() and 'isactive' not in label.lower():
                indices['stress'] = i
            elif 'rel' in label.lower() and 'isactive' not in label.lower():
                indices['relaxation'] = i
                
        return indices
        
    def read_new_data(self):
        """
        è¯»å–æ–‡ä»¶ä¸­çš„æ–°æ•°æ®
        
        Returns:
        --------
        list: æ–°æ•°æ®è¡Œåˆ—è¡¨
        """
        if not self.met_file_path or not os.path.exists(self.met_file_path):
            return []
            
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(self.met_file_path)
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡è¯»å–ï¼Œè·å–åˆ—ç´¢å¼•æ˜ å°„
            if not hasattr(self, 'column_indices'):
                self.column_indices = self.parse_met_labels(df.columns.tolist())
                print(f"âœ“ è§£æåˆ—æ˜ å°„: {self.column_indices}")
                
            # è·å–æ–°æ•°æ®ï¼ˆä»ä¸Šæ¬¡å¤„ç†ä½ç½®å¼€å§‹ï¼‰
            new_rows = df.iloc[self.last_row_processed:].copy()
            self.last_row_processed = len(df)
            
            return new_rows
            
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ–‡ä»¶é”™è¯¯: {e}")
            return []
            
    def extract_metrics(self, row):
        """
        ä»æ•°æ®è¡Œä¸­æå–performance metrics
        
        Parameters:
        -----------
        row : pandas.Series
            æ•°æ®è¡Œ
            
        Returns:
        --------
        dict: æå–çš„æŒ‡æ ‡å­—å…¸
        """
        metrics = {}
        
        for metric_name, col_index in self.column_indices.items():
            if col_index < len(row):
                value = row.iloc[col_index] if hasattr(row, 'iloc') else row[col_index]
                # å¤„ç†Noneå€¼å’Œæ— æ•ˆå€¼
                metrics[metric_name] = float(value) if pd.notna(value) else 0.0
            else:
                metrics[metric_name] = 0.0
                
        # ç¡®ä¿æ‰€æœ‰éœ€è¦çš„æŒ‡æ ‡éƒ½æœ‰å€¼
        for weight_key in self.weights.keys():
            if weight_key not in metrics:
                metrics[weight_key] = 0.0
                
        return metrics
        
    def calculate_composite_score(self, metrics):
        """
        è®¡ç®—ç»¼åˆå”¤é†’åº¦åˆ†æ•°ï¼ˆä¸alg.pyç®—æ³•ä¸€è‡´ï¼‰
        
        Parameters:
        -----------
        metrics : dict
            performance metricså­—å…¸
            
        Returns:
        --------
        float: ç»¼åˆåˆ†æ•°
        """
        composite = (
            metrics['attention'] * self.weights['attention'] +
            metrics['engagement'] * self.weights['engagement'] +
            metrics['excitement'] * self.weights['excitement'] +
            metrics['interest'] * self.weights['interest'] +
            metrics['stress'] * self.weights['stress'] +
            metrics['relaxation'] * self.weights['relaxation']
        )
        return composite
        
    def apply_algorithm(self, data_window):
        """
        åº”ç”¨ç®—æ³•è¿›è¡Œåˆ†æï¼ˆåŸºäºalg.pyé€»è¾‘ï¼‰
        
        Parameters:
        -----------
        data_window : list
            æ•°æ®çª—å£
            
        Returns:
        --------
        dict: åˆ†æç»“æœ
        """
        if len(data_window) < 3:
            return None
            
        # æå–ç»¼åˆåˆ†æ•°åºåˆ—
        composite_scores = []
        latest_metrics = None
        
        for timestamp, metrics in data_window:
            score = self.calculate_composite_score(metrics)
            composite_scores.append(score)
            latest_metrics = metrics
            
        # è½¬æ¢ä¸ºnumpyæ•°ç»„è¿›è¡Œå¤„ç†
        comp_array = np.array(composite_scores)
        
        # å½’ä¸€åŒ–ï¼ˆä¸alg.pyä¸€è‡´ï¼‰
        if comp_array.max() > comp_array.min():
            normalized = (comp_array - comp_array.min()) / (comp_array.max() - comp_array.min())
        else:
            normalized = np.ones_like(comp_array) * 0.5
            
        # å¹³æ»‘å¤„ç†ï¼ˆ3ç‚¹ç§»åŠ¨å¹³å‡ï¼‰
        if len(normalized) >= 3:
            smooth_series = pd.Series(normalized).rolling(3, center=True).mean().fillna(method='bfill')
            smooth_scores = smooth_series.values
        else:
            smooth_scores = normalized
            
        # å½“å‰åˆ†æ•°
        current_score = smooth_scores[-1]
        
        # ç®€åŒ–çš„åˆ†ç±»åˆ¤æ–­ï¼ˆåŸºäºé˜ˆå€¼0.65ï¼‰
        undisturbed = 1 if current_score > 0.65 else 0
        
        # æ„å»ºç»“æœ
        result = {
            'timestamp': time.time(),
            'composite_score': comp_array[-1],
            'normalized_score': current_score,
            'undisturbed_classification': undisturbed,
            'metrics': latest_metrics,
            'buffer_size': len(data_window)
        }
        
        return result
        
    def process_data_batch(self, new_data):
        """
        å¤„ç†ä¸€æ‰¹æ–°æ•°æ®
        
        Parameters:
        -----------
        new_data : pandas.DataFrame
            æ–°æ•°æ®æ‰¹æ¬¡
        """
        if new_data.empty:
            return
            
        # å°†æ–°æ•°æ®æ·»åŠ åˆ°ç¼“å†²åŒº
        for _, row in new_data.iterrows():
            timestamp = row.iloc[0] if 'timestamp' in row.index or len(row) > 0 else time.time()
            metrics = self.extract_metrics(row)
            self.data_buffer.append((timestamp, metrics))
            
        # åº”ç”¨ç®—æ³•åˆ†æ
        if len(self.data_buffer) >= 3:
            result = self.apply_algorithm(list(self.data_buffer))
            
            if result:
                # ä¿å­˜ç»“æœ
                self.analysis_results.append(result)
                
                # è¾“å‡ºåˆ°ç»ˆç«¯
                self.display_result(result)
                
    def display_result(self, result):
        """
        åœ¨ç»ˆç«¯æ˜¾ç¤ºåˆ†æç»“æœ
        
        Parameters:
        -----------
        result : dict
            åˆ†æç»“æœ
        """
        # çŠ¶æ€å›¾æ ‡å’Œæ–‡å­—
        status = "ğŸ¯ ä¸“æ³¨çŠ¶æ€" if result['undisturbed_classification'] == 1 else "ğŸ˜´ åˆ†æ•£çŠ¶æ€"
        
        # æ ¼å¼åŒ–è¾“å‡º
        current_time = datetime.now().strftime('%H:%M:%S')
        metrics = result['metrics']
        
        print(f"\n{status} | {current_time}")
        print(f"  ç»¼åˆåˆ†æ•°: {result['normalized_score']:.3f}")
        print(f"  æ³¨æ„åŠ›: {metrics['attention']:.2f} | å‚ä¸åº¦: {metrics['engagement']:.2f}")
        print(f"  å…´å¥‹åº¦: {metrics['excitement']:.2f} | å…´è¶£åº¦: {metrics['interest']:.2f}")
        print(f"  å‹åŠ›å€¼: {metrics['stress']:.2f} | æ”¾æ¾åº¦: {metrics['relaxation']:.2f}")
        print(f"  æ•°æ®ç‚¹: {result['buffer_size']}")
        print("-" * 50)
        
    def start_processing(self):
        """
        å¼€å§‹å®æ—¶å¤„ç†
        """
        print(f"\nğŸš€ å¯åŠ¨å®æ—¶å¤„ç†å™¨")
        print(f"  å¤„ç†é—´éš”: {self.processing_interval} ç§’")
        print(f"  ç®—æ³•æƒé‡: {self.weights}")
        
        # ç­‰å¾…æ•°æ®æ–‡ä»¶
        if not self.wait_for_data_file():
            return False
            
        self.is_running = True
        print(f"\nğŸ“Š å¼€å§‹å®æ—¶æ•°æ®å¤„ç†: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 60)
        
        try:
            while self.is_running:
                # è¯»å–æ–°æ•°æ®
                new_data = self.read_new_data()
                
                if not new_data.empty:
                    self.process_data_batch(new_data)
                    
                # ç­‰å¾…ä¸‹ä¸ªå¤„ç†å‘¨æœŸ
                time.sleep(self.processing_interval)
                
        except KeyboardInterrupt:
            print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¤„ç†")
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            self.stop_processing()
            
    def stop_processing(self):
        """
        åœæ­¢å¤„ç†
        """
        self.is_running = False
        print(f"\nğŸ›‘ åœæ­¢å®æ—¶å¤„ç†")
        self.print_summary()
        
    def print_summary(self):
        """
        æ‰“å°å¤„ç†æ€»ç»“
        """
        if not self.analysis_results:
            print("ğŸ“Š æ²¡æœ‰ç”Ÿæˆåˆ†æç»“æœ")
            return
            
        print("\n" + "=" * 60)
        print("å®æ—¶å¤„ç†æ€»ç»“")
        print("=" * 60)
        
        total_analyses = len(self.analysis_results)
        undisturbed_count = sum(1 for r in self.analysis_results if r['undisturbed_classification'] == 1)
        undisturbed_percentage = (undisturbed_count / total_analyses) * 100
        
        print(f"  æ€»åˆ†ææ¬¡æ•°: {total_analyses}")
        print(f"  ä¸“æ³¨çŠ¶æ€: {undisturbed_count} æ¬¡ ({undisturbed_percentage:.1f}%)")
        print(f"  åˆ†æ•£çŠ¶æ€: {total_analyses - undisturbed_count} æ¬¡ ({100-undisturbed_percentage:.1f}%)")
        
        if self.analysis_results:
            avg_attention = np.mean([r['metrics']['attention'] for r in self.analysis_results])
            avg_engagement = np.mean([r['metrics']['engagement'] for r in self.analysis_results])
            avg_composite = np.mean([r['normalized_score'] for r in self.analysis_results])
            
            print(f"  å¹³å‡æ³¨æ„åŠ›: {avg_attention:.2f}")
            print(f"  å¹³å‡å‚ä¸åº¦: {avg_engagement:.2f}")
            print(f"  å¹³å‡ç»¼åˆåˆ†æ•°: {avg_composite:.3f}")


def main():
    """
    ä¸»å‡½æ•°
    """
    print("EMOTIV å®æ—¶æ•°æ®å¤„ç†å™¨")
    print("=" * 60)
    print("ğŸ“‹ ä½¿ç”¨è¯´æ˜:")
    print("1. è¯·å…ˆè¿è¡Œ data_collector_test.py å¼€å§‹æ•°æ®é‡‡é›†")
    print("2. ç„¶åè¿è¡Œæ­¤è„šæœ¬è¿›è¡Œå®æ—¶å¤„ç†")
    print("3. å¤„ç†å™¨å°†æ¯2ç§’è¾“å‡ºä¸€æ¬¡åˆ†æç»“æœ")
    print("4. æŒ‰ Ctrl+C å¯ä»¥åœæ­¢å¤„ç†")
    
    print("\nâš ï¸  ç¡®è®¤æ•°æ®é‡‡é›†å™¨å·²ç»è¿è¡Œï¼ŸæŒ‰ Enter ç»§ç»­ï¼ŒCtrl+C é€€å‡º...")
    try:
        input()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆ")
        return
    
    try:
        # åˆ›å»ºå¤„ç†å™¨
        processor = RealtimeProcessor()
        
        # å¼€å§‹å¤„ç†
        processor.start_processing()
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()